{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError, Huber, LogCosh\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE LSTM(124) BIDIRECTIONAL LAYER WITH 4 FEATURES AND 90% OF DATA IS TRAINING, 7.5% VALIDATION, 2.5% TEST\\\n",
    "# 30 weeks\n",
    "# 100 EPOCHS WITH 32 BATCHES\n",
    "# RSI OF PERIOD 7 AND AROON OF 14\n",
    "start_date = pd.to_datetime('19900101').tz_localize('America/New_York')\n",
    "sequence_length = 2\n",
    "epochs = 100\n",
    "batches = 32\n",
    "features = ['Close', 'RSI', 'AroonUp', 'AroonDown']\n",
    "\n",
    "rsi_period=7\n",
    "aroon_period=14\n",
    "\n",
    "training_scaler = 0.9\n",
    "validation_scaler = 0.075\n",
    "test_scaler = 0.025\n",
    "\n",
    "lstm_complexity = 124\n",
    "out_pred = 1\n",
    "\n",
    "# SINGLE LSTM(124) BIDIRECTIONAL LAYER WITH 4 FEATURES AND 85% OF DATA IS TRAINING, 12,5%% VALIDATION, 2.5% TEST\n",
    "# 30 weeks\n",
    "# 100 EPOCHS WITH 32 BATCHES\n",
    "# RSI OF PERIOD 7 AND AROON OF 14\n",
    "# THIS ONE LOOKS MORE IMPRECISE BUT IS RESULTING IN MORE GAINS\n",
    "start_date = pd.to_datetime('19900101').tz_localize('America/New_York')\n",
    "sequence_length = 2\n",
    "epochs = 100\n",
    "batches = 32\n",
    "features = ['Close', 'RSI', 'AroonUp', 'AroonDown']\n",
    "\n",
    "rsi_period=7\n",
    "aroon_period=14\n",
    "\n",
    "training_scaler = 0.85\n",
    "validation_scaler = 0.125\n",
    "test_scaler = 0.025\n",
    "\n",
    "lstm_complexity = 124\n",
    "out_pred = 1\n",
    "\n",
    "# SINGLE LSTM(124) BIDIRECTIONAL LAYER WITH 4 FEATURES AND 80% OF DATA IS TRAINING, 17.5% VALIDATION, 2.5% TEST\n",
    "# 40 weeks\n",
    "# 100 EPOCHS WITH 32 BATCHES\n",
    "# RSI OF PERIOD 7 AND MACD OF 12-26-9\n",
    "# THIS ONE LOOKS INCREDIBLY PRECISE. BEST GAINS YET (AMAZING??)\n",
    "start_date = pd.to_datetime('19900101').tz_localize('America/New_York')\n",
    "sequence_length = 2\n",
    "epochs = 100\n",
    "batches = 32\n",
    "features = ['Close', 'RSI', 'MACD_Hist', 'Signal']\n",
    "\n",
    "# RSI PARAMS\n",
    "rsi_period=7\n",
    "\n",
    "#MACD PARAMS\n",
    "fast_period = 12\n",
    "slow_period = 26\n",
    "signal_period = 9\n",
    "\n",
    "training_scaler = 0.8\n",
    "validation_scaler = 0.175\n",
    "test_scaler = 0.025\n",
    "\n",
    "lstm_complexity = 124\n",
    "out_pred = 1\n",
    "\n",
    "# SINGLE LSTM(124) BIDIRECTIONAL LAYER WITH 4 FEATURES AND 80% OF DATA IS TRAINING, 17.5% VALIDATION, 2.5% TEST\n",
    "# 40 weeks\n",
    "# 100 EPOCHS WITH 32 BATCHES\n",
    "# RSI OF PERIOD 7 AND MACD OF 12-26-9\n",
    "# Dense layer 7 predictions\n",
    "start_date = pd.to_datetime('19900101').tz_localize('America/New_York')\n",
    "sequence_length = 2\n",
    "epochs = 100\n",
    "batches = 32\n",
    "features = ['Close', 'RSI', 'MACD_Hist', 'Signal']\n",
    "\n",
    "# RSI PARAMS\n",
    "rsi_period=7\n",
    "\n",
    "#MACD PARAMS\n",
    "fast_period = 12\n",
    "slow_period = 26\n",
    "signal_period = 9\n",
    "\n",
    "training_scaler = 0.8\n",
    "validation_scaler = 0.175\n",
    "test_scaler = 0.025\n",
    "\n",
    "lstm_complexity = 124\n",
    "out_pred = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('19900101').tz_localize('America/New_York')\n",
    "sequence_length = 2\n",
    "epochs = 100\n",
    "batches = 32\n",
    "features = ['Close', 'macd_hist', 'macd_signal', 'aroon_up', 'aroon_down']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_rsi(df:pd.DataFrame, period=7):\n",
    "    delta = df['Close'].diff()\n",
    "    delta = delta.dropna()\n",
    "\n",
    "    gain, loss = delta.clip(lower=0), delta.clip(upper=0, lower=None)\n",
    "\n",
    "    # Use Exponential Moving Average for smoother RSI\n",
    "    ema_up = gain.ewm(alpha=1/period, min_periods=period).mean()\n",
    "    ema_down = loss.abs().ewm(alpha=1/period, min_periods=period).mean()\n",
    "\n",
    "    rs = ema_up / ema_down\n",
    "    print(rs)\n",
    "    \n",
    "    df.loc[df.index[-len(rs):], 'rsi'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_aroon(df:pd.DataFrame, period=25):\n",
    "    \"\"\"\n",
    "    Compute Aroon Up and Aroon Down for a given DataFrame.\n",
    "\n",
    "    :param df: DataFrame with 'high_price' and 'low_price' columns.\n",
    "    :param period: Lookback period for Aroon calculation.\n",
    "    :return: DataFrame with added 'aroon_up' and 'aroon_down' columns.\n",
    "    \"\"\"\n",
    "    # Computar Aroon Up\n",
    "    df['aroon_up'] = (df['High']\n",
    "                            .rolling(window=period+1, min_periods=period)\n",
    "                            .apply(lambda x: (x.argmax() / period), raw=True)*100\n",
    "    )\n",
    "    \n",
    "    # Computar Aroon Up\n",
    "    df['aroon_down'] = (df['Low']\n",
    "                                .rolling(window=period+1, min_periods=period)\n",
    "                                .apply(lambda x: (x.argmin() / period), raw=True)*100\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_obv(df):\n",
    "        df[\"obv\"] = np.where(df[\"Close\"] > df[\"Close\"].shift(1), df[\"Volume\"], \n",
    "             np.where(df[\"Close\"] < df[\"Close\"].shift(1), -df[\"Volume\"], 0))\n",
    "        \n",
    "        df[\"obv\"] = df[\"obv\"].cumsum()\n",
    "        \n",
    "        return df\n",
    "\n",
    "def add_macd(df:pd.DataFrame, fast_period=fast_period, slow_period=slow_period, signal_period=signal_period):\n",
    "    \"\"\"\n",
    "    Adds MACD, Signal line, and MACD Histogram to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the 'Close' price column.\n",
    "    fast_period (int): Period for the fast EMA (default is 12).\n",
    "    slow_period (int): Period for the slow EMA (default is 26).\n",
    "    signal_period (int): Period for the signal line EMA (default is 9).\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with added MACD, Signal line, and MACD Histogram columns.\n",
    "    \"\"\"\n",
    "    # Calculate the fast and slow EMAs\n",
    "    df['EMA_fast'] = df['Close'].ewm(span=fast_period, adjust=False).mean()\n",
    "    df['EMA_slow'] = df['Close'].ewm(span=slow_period, adjust=False).mean()\n",
    "    \n",
    "    # Calculate the MACD\n",
    "    df['macd'] = df['EMA_fast'] - df['EMA_slow']\n",
    "    \n",
    "    # Calculate the Signal line\n",
    "    df['macd_signal'] = df['macd'].ewm(span=signal_period, adjust=False).mean()\n",
    "    \n",
    "    # Calculate the MACD Histogram\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # Drop the intermediate EMA columns\n",
    "    df.drop(columns=['EMA_fast', 'EMA_slow'], inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBTAINING DATA\n",
    "1) Tickers\n",
    "2) Data treatment\n",
    "3) Sequence creation\n",
    "4) Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list=[]\n",
    "\n",
    "ticker_list.append(yf.Ticker(\"GOOG\"))\n",
    "# ticker_list.append(yf.Ticker(\"GOOG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Open    High     Low   Close   Volume\n",
      "Date                                                              \n",
      "2022-02-08 09:30:00-05:00  301.27  303.14  300.10  300.36  2265800\n",
      "2022-02-08 10:00:00-05:00  300.38  302.40  299.95  301.21  1593871\n",
      "2022-02-08 10:30:00-05:00  301.22  303.08  300.42  302.34  1235479\n",
      "2022-02-08 11:00:00-05:00  302.32  304.82  302.28  304.21  1297360\n",
      "2022-02-08 11:30:00-05:00  304.23  305.13  304.14  304.40  1160990\n",
      "------\n",
      "                             Open    High     Low   Close   Volume  \\\n",
      "Date                                                                 \n",
      "2024-05-23 12:30:00-04:00  432.04  432.10  430.26  430.29   250137   \n",
      "2024-05-23 13:00:00-04:00  430.29  430.62  429.61  430.10   340650   \n",
      "2024-05-23 13:30:00-04:00  430.10  430.10  427.19  427.39   492265   \n",
      "2024-05-23 14:00:00-04:00  427.34  428.01  426.77  427.06   333748   \n",
      "2024-05-23 14:30:00-04:00  427.05  427.24  425.80  425.95   416768   \n",
      "2024-05-23 15:00:00-04:00  425.92  426.43  425.42  425.97   495559   \n",
      "2024-05-23 15:30:00-04:00  425.98  427.44  425.86  427.15   740593   \n",
      "2024-05-24 09:30:00-04:00  427.23  427.41  424.41  425.51  1182275   \n",
      "2024-05-24 10:00:00-04:00  425.51  427.28  425.36  427.01   591714   \n",
      "2024-05-24 10:30:00-04:00  427.04  428.16  426.87  427.94   398607   \n",
      "2024-05-24 11:00:00-04:00  427.95  429.66  427.95  429.25   390102   \n",
      "2024-05-24 11:30:00-04:00  429.25  429.97  428.77  429.78   349470   \n",
      "2024-05-24 12:00:00-04:00  429.74  430.34  429.63  430.10   273960   \n",
      "2024-05-24 12:30:00-04:00  430.13  430.15  429.35  429.73   179671   \n",
      "2024-05-24 13:00:00-04:00  429.73  430.47  429.62  430.27   199487   \n",
      "2024-05-24 13:30:00-04:00  430.24  430.52  429.82  430.40   207596   \n",
      "2024-05-24 14:00:00-04:00  430.39  431.06  430.32  430.41   303260   \n",
      "2024-05-24 14:30:00-04:00  430.40  430.53  429.73  429.73   236031   \n",
      "2024-05-24 15:00:00-04:00  429.71  430.09  429.16  429.82   256019   \n",
      "2024-05-24 15:30:00-04:00  429.82  430.45  429.53  430.13   715303   \n",
      "\n",
      "                             aroon_up  aroon_down      macd  macd_signal  \\\n",
      "Date                                                                       \n",
      "2024-05-23 12:30:00-04:00   57.142857   42.857143  0.771080     0.771074   \n",
      "2024-05-23 13:00:00-04:00   50.000000   35.714286  0.667170     0.750293   \n",
      "2024-05-23 13:30:00-04:00   42.857143   28.571429  0.361973     0.672629   \n",
      "2024-05-23 14:00:00-04:00   35.714286  100.000000  0.092409     0.556585   \n",
      "2024-05-23 14:30:00-04:00   28.571429  100.000000 -0.208389     0.403590   \n",
      "2024-05-23 15:00:00-04:00   21.428571  100.000000 -0.440086     0.234855   \n",
      "2024-05-23 15:30:00-04:00   14.285714   92.857143 -0.522468     0.083390   \n",
      "2024-05-24 09:30:00-04:00    7.142857  100.000000 -0.711885    -0.075665   \n",
      "2024-05-24 10:00:00-04:00    0.000000   92.857143 -0.732518    -0.207035   \n",
      "2024-05-24 10:30:00-04:00    7.142857   85.714286 -0.666148    -0.298858   \n",
      "2024-05-24 11:00:00-04:00    0.000000   78.571429 -0.502055    -0.339497   \n",
      "2024-05-24 11:30:00-04:00    7.142857   71.428571 -0.325492    -0.336696   \n",
      "2024-05-24 12:00:00-04:00    0.000000   64.285714 -0.157923    -0.300942   \n",
      "2024-05-24 12:30:00-04:00    7.142857   57.142857 -0.054352    -0.251624   \n",
      "2024-05-24 13:00:00-04:00    0.000000   50.000000  0.070489    -0.187201   \n",
      "2024-05-24 13:30:00-04:00    0.000000   42.857143  0.177866    -0.114188   \n",
      "2024-05-24 14:00:00-04:00  100.000000   35.714286  0.260765    -0.039197   \n",
      "2024-05-24 14:30:00-04:00   92.857143   28.571429  0.268497     0.022342   \n",
      "2024-05-24 15:00:00-04:00   85.714286   21.428571  0.278674     0.073608   \n",
      "2024-05-24 15:30:00-04:00   78.571429   14.285714  0.308202     0.120527   \n",
      "\n",
      "                           macd_hist  target  \n",
      "Date                                          \n",
      "2024-05-23 12:30:00-04:00   0.000006  430.29  \n",
      "2024-05-23 13:00:00-04:00  -0.083123  430.10  \n",
      "2024-05-23 13:30:00-04:00  -0.310656  427.39  \n",
      "2024-05-23 14:00:00-04:00  -0.464176  427.06  \n",
      "2024-05-23 14:30:00-04:00  -0.611979  425.95  \n",
      "2024-05-23 15:00:00-04:00  -0.674941  425.97  \n",
      "2024-05-23 15:30:00-04:00  -0.605859  427.15  \n",
      "2024-05-24 09:30:00-04:00  -0.636221  425.51  \n",
      "2024-05-24 10:00:00-04:00  -0.525483  427.01  \n",
      "2024-05-24 10:30:00-04:00  -0.367290  427.94  \n",
      "2024-05-24 11:00:00-04:00  -0.162558  429.25  \n",
      "2024-05-24 11:30:00-04:00   0.011204  429.78  \n",
      "2024-05-24 12:00:00-04:00   0.143019  430.10  \n",
      "2024-05-24 12:30:00-04:00   0.197271  429.73  \n",
      "2024-05-24 13:00:00-04:00   0.257690  430.27  \n",
      "2024-05-24 13:30:00-04:00   0.292054  430.40  \n",
      "2024-05-24 14:00:00-04:00   0.299962  430.41  \n",
      "2024-05-24 14:30:00-04:00   0.246155  429.73  \n",
      "2024-05-24 15:00:00-04:00   0.205066  429.82  \n",
      "2024-05-24 15:30:00-04:00   0.187675  430.13  \n"
     ]
    }
   ],
   "source": [
    "df_scaled_list = []\n",
    "\n",
    "# RSI PARAMS\n",
    "rsi_period=14\n",
    "\n",
    "#AROON PARAMS\n",
    "aroon_period = 14\n",
    "\n",
    "#MACD PARAMS\n",
    "fast_period = 12\n",
    "slow_period = 26\n",
    "signal_period = 9\n",
    "\n",
    "training_scaler = 0.8\n",
    "validation_scaler = 0.175\n",
    "test_scaler = 0.025\n",
    "\n",
    "lstm_complexity = 128*2\n",
    "\n",
    "\n",
    "# data = ticker.history(period='max')\n",
    "\n",
    "# data = data[data.index>=start_date]\n",
    "data = pd.read_csv('MSFT_30.csv', sep=';', index_col=0)\n",
    "# data.drop(columns=['id', 'ticker_id', 'aroon_down', 'aroon_up', 'macd', 'macd_hist', 'macd_signal', 'rsi', 'created_at', 'updated_at', 'obv'], inplace=True)\n",
    "data.sort_index(ascending=True, inplace=True)\n",
    "print(data.head(5))\n",
    "\n",
    "# data = calculate_rsi(data, rsi_period)\n",
    "data = calculate_aroon(data, aroon_period)\n",
    "data = add_macd(data)\n",
    "# data = add_obv(data)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data['target'] = data['Close']\n",
    "\n",
    "print('------')\n",
    "print(data.tail(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7665, 6)\n",
      "                            Close  macd_hist  macd_signal   aroon_up  \\\n",
      "Date                                                                   \n",
      "2022-02-09 09:30:00-05:00  309.28   0.412986     0.981777  92.857143   \n",
      "2022-02-09 10:00:00-05:00  307.95   0.474766     1.100469  92.857143   \n",
      "2022-02-09 10:30:00-05:00  308.65   0.523241     1.231279  85.714286   \n",
      "2022-02-09 11:00:00-05:00  308.35   0.495824     1.355235  78.571429   \n",
      "2022-02-09 11:30:00-05:00  307.89   0.410936     1.457969  71.428571   \n",
      "2022-02-09 12:00:00-05:00  308.67   0.372674     1.551137  64.285714   \n",
      "2022-02-09 12:30:00-05:00  308.92   0.330968     1.633879  57.142857   \n",
      "2022-02-09 13:00:00-05:00  308.69   0.257905     1.698355  50.000000   \n",
      "2022-02-09 13:30:00-05:00  308.59   0.176725     1.742537  42.857143   \n",
      "2022-02-09 14:00:00-05:00  309.79   0.177273     1.786855  35.714286   \n",
      "2022-02-09 14:30:00-05:00  309.46   0.130974     1.819598  28.571429   \n",
      "2022-02-09 15:00:00-05:00  310.02   0.114237     1.848158  21.428571   \n",
      "2022-02-09 15:30:00-05:00  311.21   0.156852     1.887371  14.285714   \n",
      "2022-02-10 09:30:00-05:00  307.35  -0.088203     1.865320   7.142857   \n",
      "2022-02-10 10:00:00-05:00  306.41  -0.314169     1.786778   0.000000   \n",
      "2022-02-10 10:30:00-05:00  306.21  -0.468385     1.669682  78.571429   \n",
      "2022-02-10 11:00:00-05:00  305.28  -0.615063     1.515916  71.428571   \n",
      "2022-02-10 11:30:00-05:00  305.85  -0.652200     1.352866  64.285714   \n",
      "2022-02-10 12:00:00-05:00  306.68  -0.600652     1.202703  57.142857   \n",
      "2022-02-10 12:30:00-05:00  304.31  -0.699068     1.027936  50.000000   \n",
      "\n",
      "                           aroon_down  target  \n",
      "Date                                           \n",
      "2022-02-09 09:30:00-05:00    7.142857  309.28  \n",
      "2022-02-09 10:00:00-05:00    7.142857  307.95  \n",
      "2022-02-09 10:30:00-05:00    0.000000  308.65  \n",
      "2022-02-09 11:00:00-05:00    0.000000  308.35  \n",
      "2022-02-09 11:30:00-05:00    0.000000  307.89  \n",
      "2022-02-09 12:00:00-05:00   50.000000  308.67  \n",
      "2022-02-09 12:30:00-05:00   42.857143  308.92  \n",
      "2022-02-09 13:00:00-05:00   35.714286  308.69  \n",
      "2022-02-09 13:30:00-05:00   28.571429  308.59  \n",
      "2022-02-09 14:00:00-05:00   21.428571  309.79  \n",
      "2022-02-09 14:30:00-05:00   14.285714  309.46  \n",
      "2022-02-09 15:00:00-05:00    7.142857  310.02  \n",
      "2022-02-09 15:30:00-05:00    0.000000  311.21  \n",
      "2022-02-10 09:30:00-05:00  100.000000  307.35  \n",
      "2022-02-10 10:00:00-05:00   92.857143  306.41  \n",
      "2022-02-10 10:30:00-05:00   85.714286  306.21  \n",
      "2022-02-10 11:00:00-05:00   78.571429  305.28  \n",
      "2022-02-10 11:30:00-05:00   71.428571  305.85  \n",
      "2022-02-10 12:00:00-05:00   64.285714  306.68  \n",
      "2022-02-10 12:30:00-05:00  100.000000  304.31  \n",
      "                              Close  macd_hist  macd_signal  aroon_up  \\\n",
      "Date                                                                    \n",
      "2022-02-09 09:30:00-05:00  5.641695   5.376593     6.302588  9.285714   \n",
      "2022-02-09 10:00:00-05:00  5.562745   5.507975     6.431412  9.285714   \n",
      "2022-02-09 10:30:00-05:00  5.604298   5.611061     6.573390  8.571429   \n",
      "2022-02-09 11:00:00-05:00  5.586489   5.552756     6.707927  7.857143   \n",
      "2022-02-09 11:30:00-05:00  5.559183   5.372234     6.819431  7.142857   \n",
      "\n",
      "                           aroon_down  target  \n",
      "Date                                           \n",
      "2022-02-09 09:30:00-05:00    0.714286  309.28  \n",
      "2022-02-09 10:00:00-05:00    0.714286  307.95  \n",
      "2022-02-09 10:30:00-05:00    0.000000  308.65  \n",
      "2022-02-09 11:00:00-05:00    0.000000  308.35  \n",
      "2022-02-09 11:30:00-05:00    0.000000  307.89  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = data[features + ['target']].copy()  # Ensure df is a separate copy\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head(20))\n",
    "\n",
    "train_split = int(training_scaler * len(df))  # Training set size\n",
    "val_split = int(validation_scaler * len(df))  # Validation set size\n",
    "\n",
    "# Get the actual DateTime indices for training, validation, and test splits\n",
    "train_index = df.index[:train_split]  # First part for training\n",
    "val_index = df.index[train_split:train_split+val_split]  # Validation set\n",
    "test_index = df.index[train_split+val_split:]  # Remaining test set\n",
    "\n",
    "# Fit the scaler on the training set only\n",
    "scaler.fit(df.loc[train_index, features])\n",
    "\n",
    "# Transform and reassign values\n",
    "df.loc[train_index, features] = scaler.transform(df.loc[train_index, features])\n",
    "df.loc[val_index, features] = scaler.transform(df.loc[val_index, features])\n",
    "df.loc[test_index, features] = scaler.transform(df.loc[test_index, features])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, lookback=60, forecast_horizon=2):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(lookback, len(data) - forecast_horizon + 1):  # Prevent index out of range\n",
    "        sequences.append(data.iloc[i - lookback:i].values)  # Input sequence of past 'lookback' days\n",
    "        targets.append(data.iloc[i:i + forecast_horizon]['target'].values)  # Predict next 2 days\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)  # Targets will now have shape (samples, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7665, 6)\n",
      "0.8\n",
      "0.175\n",
      "\n",
      "X length: 7662\n",
      "Train: 6128\n",
      "Val: 1339\n",
      "Test: 193\n",
      "Total size: 7660\n",
      "\n",
      "X Train:\n",
      "[[[  5.64169536   5.37659278   6.30258847   9.28571429   0.71428571\n",
      "   309.28      ]\n",
      "  [  5.56274487   5.50797503   6.43141243   9.28571429   0.71428571\n",
      "   307.95      ]\n",
      "  [  5.60429776   5.6110605    6.57338955   8.57142857   0.\n",
      "   308.65      ]]\n",
      "\n",
      " [[  5.56274487   5.50797503   6.43141243   9.28571429   0.71428571\n",
      "   307.95      ]\n",
      "  [  5.60429776   5.6110605    6.57338955   8.57142857   0.\n",
      "   308.65      ]\n",
      "  [  5.58648937   5.55275585   6.70792731   7.85714286   0.\n",
      "   308.35      ]]\n",
      "\n",
      " [[  5.60429776   5.6110605    6.57338955   8.57142857   0.\n",
      "   308.65      ]\n",
      "  [  5.58648937   5.55275585   6.70792731   7.85714286   0.\n",
      "   308.35      ]\n",
      "  [  5.55918319   5.3722339    6.81943144   7.14285714   0.\n",
      "   307.89      ]]]\n",
      "\n",
      "y Train:\n",
      "[[308.35]\n",
      " [307.89]\n",
      " [308.67]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import utils.modelmethods as mm\n",
    "\n",
    "X, y = create_sequences(df, 3, 1)\n",
    "\n",
    "print(df.shape)\n",
    "print(training_scaler)\n",
    "print(validation_scaler)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = mm.obtain_split(X, y, training_scaler, validation_scaler)\n",
    "\n",
    "print(f'\\nX length: {len(X)}')\n",
    "print(f'Train: {len(X_train)}')\n",
    "print(f'Val: {len(X_val)}')\n",
    "print(f'Test: {len(X_test)}')\n",
    "print(f'Total size: {len(X_train)+len(X_val)+len(X_test)}')\n",
    "\n",
    "print('\\nX Train:')\n",
    "print(X_train[:3])\n",
    "\n",
    "print('\\ny Train:')\n",
    "print(y_train[:3])\n",
    "\n",
    "print(X_train.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAPNCAYAAACTZj0MAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVY9JREFUeJzt3Xts19X9P/BXASmaWdQhoBVX5w0NSpWbqGwxQUk0bPxhhmiEMC9xU6J0boAX8I7zFpZQJaKGJd8wmET9GiFljkmck4wIkmgGGEUtIZbLDJShgsLnl/f7+2tHoSifWtrCeTySd+B9es7nc94kh7bPz7mUFAqFQgAAAABAwjq1dwcAAAAAoL0JyQAAAABInpAMAAAAgOQJyQAAAABInpAMAAAAgOQJyQAAAABInpAMAAAAgOQJyQAAAABInpAMAAAAgOQJyQAAAABIXtEh2ZtvvhkjR46Mk08+OUpKSuKVV175zjZLly6NCy+8MEpLS+OMM86IOXPmtLS/AAAAAND+IdmOHTuif//+UV1dfVD1P/7447jqqqvisssui1WrVsUdd9wRN954YyxevLgl/QUAAACAVldSKBQKLW5cUhIvv/xyjBo16oB1Jk2aFAsXLoz333+/seyaa66JrVu3Rk1NTUvfGgAAAABaTZc4xJYtWxbDhw9vUjZixIh8RtmB7Ny5M78a7NmzJz7//PP44Q9/mAdzAAAAAKSpUCjE9u3b863AOnXqdPiEZHV1ddGrV68mZdl9fX19fPnll3H00Ufv12b69Olx//33H+quAQAAAHCYWr9+fZxyyimHT0jWElOmTImqqqrG+23btsWpp56aP3xZWVm79g0AAACA9pNNvOrTp08ce+yxrfq6hzwk6927d2zcuLFJWXafhV3NzSLLZKdgZte+sjZCMgAAAABKWnlLrtZbuHkAQ4cOjSVLljQpe/311/NyAAAAAOgIig7J/vOf/8SqVavyK/Pxxx/nf6+trW1cKjl27NjG+rfcckusW7cufve738WaNWvi6aefjj//+c8xceLE1nwOAAAAAGi7kOydd96JCy64IL8y2d5h2d+nTp2a33/22WeNgVnmtNNOi4ULF+azx/r37x9PPvlkPPfcc/kJlwAAAADQEZQUsnMzD4MN2bp3755v4G9PMgAAAIB01R+inOiQ70kGAAAAAB2dkAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEiekAwAAACA5AnJAAAAAEhei0Ky6urqqKioiG7dusWQIUNi+fLl31p/xowZcfbZZ8fRRx8dffr0iYkTJ8ZXX33V0j4DAAAAQPuGZPPnz4+qqqqYNm1arFy5Mvr37x8jRoyITZs2NVt/7ty5MXny5Lz+6tWr4/nnn89f46677mqN/gMAAABA24dkTz31VNx0000xfvz4OPfcc2PWrFlxzDHHxAsvvNBs/bfffjsuueSSuPbaa/PZZ1dccUWMGTPmO2efAQAAAECHDMl27doVK1asiOHDh//3BTp1yu+XLVvWbJuLL744b9MQiq1bty4WLVoUV1555fftOwAAAAC0ii7FVN6yZUvs3r07evXq1aQ8u1+zZk2zbbIZZFm7Sy+9NAqFQnzzzTdxyy23fOtyy507d+ZXg/r6+mK6CQAAAAAd63TLpUuXxiOPPBJPP/10vofZSy+9FAsXLowHH3zwgG2mT58e3bt3b7yyzf4BAAAA4FApKWTTu4pYbpntP7ZgwYIYNWpUY/m4ceNi69at8b//+7/7tRk2bFhcdNFF8fjjjzeW/c///E/cfPPN8Z///CdfrnkwM8myoGzbtm1RVlZW7DMCAAAAcISor6/PJ1W1dk5U1Eyyrl27xoABA2LJkiWNZXv27Mnvhw4d2mybL774Yr8grHPnzvmfB8rnSktL84fc+wIAAACADrEnWaaqqiqfOTZw4MAYPHhwzJgxI3bs2JGfdpkZO3ZslJeX50smMyNHjsxPxLzgggtiyJAh8eGHH8a9996blzeEZQAAAABwWIVko0ePjs2bN8fUqVOjrq4uKisro6ampnEz/9ra2iYzx+65554oKSnJ/9ywYUOceOKJeUD28MMPt+6TAAAAAEBb7El2pK01BQAAAODw0iH2JAMAAACAI5GQDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDktSgkq66ujoqKiujWrVsMGTIkli9f/q31t27dGrfeemucdNJJUVpaGmeddVYsWrSopX0GAAAAgFbVpdgG8+fPj6qqqpg1a1YekM2YMSNGjBgRa9eujZ49e+5Xf9euXXH55ZfnX1uwYEGUl5fHp59+Gscdd1xrPQMAAAAAfC8lhUKhUEyDLBgbNGhQzJw5M7/fs2dP9OnTJyZMmBCTJ0/er34Wpj3++OOxZs2aOOqoo1rUyfr6+ujevXts27YtysrKWvQaAAAAABz+6g9RTlTUcstsVtiKFSti+PDh/32BTp3y+2XLljXb5tVXX42hQ4fmyy179eoV/fr1i0ceeSR27959wPfZuXNn/sB7XwAAAABwqBQVkm3ZsiUPt7Kwa2/ZfV1dXbNt1q1bly+zzNpl+5Dde++98eSTT8ZDDz10wPeZPn16ngg2XNlMNQAAAAA4bE+3zJZjZvuRPfvsszFgwIAYPXp03H333fkyzAOZMmVKPmWu4Vq/fv2h7iYAAAAACStq4/4ePXpE586dY+PGjU3Ks/vevXs32yY70TLbiyxr1+Ccc87JZ55lyze7du26X5vsBMzsAgAAAIC2UNRMsizQymaDLVmypMlMsew+23esOZdcckl8+OGHeb0GH3zwQR6eNReQAQAAAECHX25ZVVUVs2fPjj/+8Y+xevXq+NWvfhU7duyI8ePH518fO3ZsvlyyQfb1zz//PG6//fY8HFu4cGG+cX+2kT8AAAAAHHbLLTPZnmKbN2+OqVOn5ksmKysro6ampnEz/9ra2vzEywbZpvuLFy+OiRMnxvnnnx/l5eV5YDZp0qTWfRIAAAAAaKGSQqFQiA6uvr4+P+Uy28S/rKysvbsDAAAAwBGWEx3y0y0BAAAAoKMTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMlrUUhWXV0dFRUV0a1btxgyZEgsX778oNrNmzcvSkpKYtSoUS15WwAAAADoGCHZ/Pnzo6qqKqZNmxYrV66M/v37x4gRI2LTpk3f2u6TTz6JO++8M4YNG/Z9+gsAAAAA7R+SPfXUU3HTTTfF+PHj49xzz41Zs2bFMcccEy+88MIB2+zevTuuu+66uP/+++PHP/7x9+0zAAAAALRfSLZr165YsWJFDB8+/L8v0KlTfr9s2bIDtnvggQeiZ8+eccMNNxzU++zcuTPq6+ubXAAAAADQIUKyLVu25LPCevXq1aQ8u6+rq2u2zVtvvRXPP/98zJ49+6DfZ/r06dG9e/fGq0+fPsV0EwAAAAA6zumW27dvj+uvvz4PyHr06HHQ7aZMmRLbtm1rvNavX38ouwkAAABA4roUUzkLujp37hwbN25sUp7d9+7de7/6H330Ub5h/8iRIxvL9uzZ839v3KVLrF27Nk4//fT92pWWluYXAAAAAHS4mWRdu3aNAQMGxJIlS5qEXtn90KFD96vft2/feO+992LVqlWN189+9rO47LLL8r9bRgkAAADAYTeTLFNVVRXjxo2LgQMHxuDBg2PGjBmxY8eO/LTLzNixY6O8vDzfV6xbt27Rr1+/Ju2PO+64/M99ywEAAADgsAnJRo8eHZs3b46pU6fmm/VXVlZGTU1N42b+tbW1+YmXAAAAAHC4KCkUCoXo4Orr6/NTLrNN/MvKytq7OwAAAAAcYTmRKV8AAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJE9IBgAAAEDyhGQAAAAAJK9FIVl1dXVUVFREt27dYsiQIbF8+fID1p09e3YMGzYsjj/++PwaPnz4t9YHAAAAgA4fks2fPz+qqqpi2rRpsXLlyujfv3+MGDEiNm3a1Gz9pUuXxpgxY+KNN96IZcuWRZ8+feKKK66IDRs2tEb/AQAAAOB7KykUCoViGmQzxwYNGhQzZ87M7/fs2ZMHXxMmTIjJkyd/Z/vdu3fnM8qy9mPHjj2o96yvr4/u3bvHtm3boqysrJjuAgAAAHAEqT9EOVFRM8l27doVK1asyJdMNr5Ap075fTZL7GB88cUX8fXXX8cJJ5xQfG8BAAAA4BDoUkzlLVu25DPBevXq1aQ8u1+zZs1BvcakSZPi5JNPbhK07Wvnzp35tXdCCAAAAABHxOmWjz76aMybNy9efvnlfNP/A5k+fXo+ba7hypZzAgAAAECHCMl69OgRnTt3jo0bNzYpz+579+79rW2feOKJPCT7y1/+Eueff/631p0yZUq+rrThWr9+fTHdBAAAAIBDF5J17do1BgwYEEuWLGksyzbuz+6HDh16wHaPPfZYPPjgg1FTUxMDBw78zvcpLS3NN17b+wIAAACADrEnWaaqqirGjRuXh12DBw+OGTNmxI4dO2L8+PH517MTK8vLy/Mlk5nf//73MXXq1Jg7d25UVFREXV1dXv6DH/wgvwAAAADgsAvJRo8eHZs3b86DryzwqqyszGeINWzmX1tbm5942eCZZ57JT8W8+uqrm7zOtGnT4r777muNZwAAAACA76WkUCgUooPLTrfMNvDP9iez9BIAAAAgXfWHKCdq09MtAQAAAKAjEpIBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkLwWhWTV1dVRUVER3bp1iyFDhsTy5cu/tf6LL74Yffv2zeufd955sWjRopb2FwAAAADaPySbP39+VFVVxbRp02LlypXRv3//GDFiRGzatKnZ+m+//XaMGTMmbrjhhnj33Xdj1KhR+fX++++3Rv8BAAAA4HsrKRQKhWIaZDPHBg0aFDNnzszv9+zZE3369IkJEybE5MmT96s/evTo2LFjR7z22muNZRdddFFUVlbGrFmzDuo96+vro3v37rFt27YoKysrprsAAAAAHEHqD1FO1KWYyrt27YoVK1bElClTGss6deoUw4cPj2XLljXbJivPZp7tLZt59sorrxzwfXbu3JlfDbKHbvhHAAAAACBd9f8/Hypy3lfrhmRbtmyJ3bt3R69evZqUZ/dr1qxptk1dXV2z9bPyA5k+fXrcf//9+5VnM9YAAAAA4N///nc+o6xdQrK2ks1U23v22datW+NHP/pR1NbWturDA62T4GcB9vr16y2Hhg7IGIWOy/iEjs0YhY4rW3F46qmnxgknnNCqr1tUSNajR4/o3LlzbNy4sUl5dt+7d+9m22TlxdTPlJaW5te+soDMf07QMWVj0/iEjssYhY7L+ISOzRiFjivbAqxVX6+Yyl27do0BAwbEkiVLGsuyjfuz+6FDhzbbJivfu37m9ddfP2B9AAAAAGhrRS+3zJZBjhs3LgYOHBiDBw+OGTNm5KdXjh8/Pv/62LFjo7y8PN9XLHP77bfHT3/603jyySfjqquuinnz5sU777wTzz77bOs/DQAAAAC0RUg2evTo2Lx5c0ydOjXffL+ysjJqamoaN+fP9g3be7rbxRdfHHPnzo177rkn7rrrrjjzzDPzky379et30O+ZLb2cNm1as0swgfZlfELHZoxCx2V8QsdmjEJ647Ok0NrnZQIAAADAYaZ1dzgDAAAAgMOQkAwAAACA5AnJAAAAAEiekAwAAACA5HWYkKy6ujoqKiqiW7duMWTIkFi+fPm31n/xxRejb9++ef3zzjsvFi1a1GZ9hdQUMz5nz54dw4YNi+OPPz6/hg8f/p3jGWjb76EN5s2bFyUlJTFq1KhD3kdIVbHjc+vWrXHrrbfGSSedlJ/YddZZZ/k5FzrQGJ0xY0acffbZcfTRR0efPn1i4sSJ8dVXX7VZfyEVb775ZowcOTJOPvnk/OfVV1555TvbLF26NC688ML8++cZZ5wRc+bMOTxDsvnz50dVVVV+fOfKlSujf//+MWLEiNi0aVOz9d9+++0YM2ZM3HDDDfHuu+/mP9xn1/vvv9/mfYcjXbHjM/uPKRufb7zxRixbtiz/4eGKK66IDRs2tHnfIQXFjtEGn3zySdx55515qA10jPG5a9euuPzyy/PxuWDBgli7dm3+4VN5eXmb9x1SUOwYnTt3bkyePDmvv3r16nj++efz17jrrrvavO9wpNuxY0c+JrMg+2B8/PHHcdVVV8Vll10Wq1atijvuuCNuvPHGWLx4cVHvW1IoFArRzrLEftCgQTFz5sz8fs+ePfkv1hMmTMj/E9rX6NGj83+w1157rbHsoosuisrKypg1a1ab9h2OdMWOz33t3r07n1GWtR87dmwb9BjS0pIxmo3Ln/zkJ/HLX/4y/v73v+czVw7m0zng0I7P7OfYxx9/PNasWRNHHXVUO/QY0lLsGL3tttvycGzJkiWNZb/5zW/in//8Z7z11ltt2ndISUlJSbz88svfuvph0qRJsXDhwiaTp6655pr859yamprDZyZZ9onZihUr8iVZDTp16pTfZ7NQmpOV710/kyX+B6oPtN343NcXX3wRX3/9dZxwwgmHsKeQppaO0QceeCB69uyZz8gGOs74fPXVV2Po0KH5cstevXpFv3794pFHHsmDbaD9x+jFF1+ct2lYkrlu3bp8OfSVV17ZZv0G4pDmRF2inW3ZsiX/xp/9ILC37D77FK05dXV1zdbPyoH2HZ/NJfrZOvJ9/8MC2meMZp90Z8tDsmnoQMcan9kv3H/729/iuuuuy3/x/vDDD+PXv/51/mFTtrwLaN8xeu211+btLr300sgWZH3zzTdxyy23WG4JHcCBcqL6+vr48ssv830ED4uZZMCR69FHH803Bs+mxmaboQLta/v27XH99dfnexz16NGjvbsD7CNb6pXN8nz22WdjwIAB+RYjd999t+1EoIPI9t7NZnc+/fTT+R5mL730Ur6868EHH2zvrgGtpN1nkmU/pHfu3Dk2btzYpDy77927d7NtsvJi6gNtNz4bPPHEE3lI9te//jXOP//8Q9xTSFOxY/Sjjz7KNwTPTgra+5fyTJcuXfJNwk8//fQ26Dkc+VryPTQ70TLbiyxr1+Ccc87JPx3PloZ17dr1kPcbUtGSMXrvvffmHzZlm4FnzjvvvHyv7JtvvjkPtLPlmkD7OFBOVFZWdtCzyDLtPoqzb/bZJ2V7b36Y/cCe3Wd7MjQnK9+7fub1118/YH2g7cZn5rHHHss/Ucs2SBw4cGAb9RbSU+wY7du3b7z33nv5UsuG62c/+1njKUDZZsVA+30PveSSS/Illg3hdeaDDz7IwzMBGbT/GM322t03CGsItTvAeXiQtKGtlRMVOoB58+YVSktLC3PmzCn861//Ktx8882F4447rlBXV5d//frrry9Mnjy5sf4//vGPQpcuXQpPPPFEYfXq1YVp06YVjjrqqMJ7773Xjk8BR6Zix+ejjz5a6Nq1a2HBggWFzz77rPHavn17Oz4FHLmKHaP7GjduXOHnP/95G/YY0lHs+KytrS0ce+yxhdtuu62wdu3awmuvvVbo2bNn4aGHHmrHp4AjV7FjNPu9Mxujf/rTnwrr1q0r/OUvfymcfvrphV/84hft+BRwZNq+fXvh3Xffza8sunrqqafyv3/66af517OxmY3RBtmYPOaYYwq//e1v85yourq60Llz50JNTU1R79vuyy0z2X4LmzdvjqlTp+bTySsrK/MZKA2brtXW1jZJ7LNTRebOnRv33HNPvknimWeemR9dn50ABLTv+HzmmWfyJSFXX311k9fJNhy+77772rz/cKQrdowCHXd8ZrM5Fy9eHBMnTsy3KigvL4/bb789PwQHaP8xmv3+WVJSkv+5YcOGOPHEE/MtDB5++OF2fAo4Mr3zzjv5aocGVVVV+Z/jxo2LOXPmxGeffZaP0QannXZavkdg9j30D3/4Q5xyyinx3HPP5SdcFqMkS8pa8TkAAAAA4LDjo2UAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5RYdkb775ZowcOTJOPvnkKCkpiVdeeeU72yxdujQuvPDCKC0tjTPOOCPmzJnT0v4CAAAAQPuHZDt27Ij+/ftHdXX1QdX/+OOP46qrrorLLrssVq1aFXfccUfceOONsXjx4pb0FwAAAABaXUmhUCi0uHFJSbz88ssxatSoA9aZNGlSLFy4MN5///3GsmuuuSa2bt0aNTU1LX1rAAAAAGg1XeIQW7ZsWQwfPrxJ2YgRI/IZZQeyc+fO/GqwZ8+e+Pzzz+OHP/xhHswBAAAAkKZCoRDbt2/PtwLr1KnT4ROS1dXVRa9evZqUZff19fXx5ZdfxtFHH71fm+nTp8f9999/qLsGAAAAwGFq/fr1ccoppxw+IVlLTJkyJaqqqhrvt23bFqeeemr+8GVlZe3aNwAAAADaTzbxqk+fPnHssce26use8pCsd+/esXHjxiZl2X0WdjU3iyyTnYKZXfvK2gjJAAAAAChp5S25Wm/h5gEMHTo0lixZ0qTs9ddfz8sBAAAAoCMoOiT7z3/+E6tWrcqvzMcff5z/vba2tnGp5NixYxvr33LLLbFu3br43e9+F2vWrImnn346/vznP8fEiRNb8zkAAAAAoO1CsnfeeScuuOCC/Mpke4dlf586dWp+/9lnnzUGZpnTTjstFi5cmM8e69+/fzz55JPx3HPP5SdcAgAAAEBHUFLIzs08DDZk6969e76Bvz3JAAAAANJVf4hyokO+JxkAAAAAdHRCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHktCsmqq6ujoqIiunXrFkOGDInly5d/a/0ZM2bE2WefHUcffXT06dMnJk6cGF999VVL+wwAAAAA7RuSzZ8/P6qqqmLatGmxcuXK6N+/f4wYMSI2bdrUbP25c+fG5MmT8/qrV6+O559/Pn+Nu+66qzX6DwAAAABtH5I99dRTcdNNN8X48ePj3HPPjVmzZsUxxxwTL7zwQrP133777bjkkkvi2muvzWefXXHFFTFmzJjvnH0GAAAAAB0yJNu1a1esWLEihg8f/t8X6NQpv1+2bFmzbS6++OK8TUMotm7duli0aFFceeWV37fvAAAAANAquhRTecuWLbF79+7o1atXk/Lsfs2aNc22yWaQZe0uvfTSKBQK8c0338Qtt9zyrcstd+7cmV8N6uvri+kmAAAAAHSs0y2XLl0ajzzySDz99NP5HmYvvfRSLFy4MB588MEDtpk+fXp079698co2+wcAAACAQ6WkkE3vKmK5Zbb/2IIFC2LUqFGN5ePGjYutW7fG//7v/+7XZtiwYXHRRRfF448/3lj2P//zP3HzzTfHf/7zn3y55sHMJMuCsm3btkVZWVmxzwgAAADAEaK+vj6fVNXaOVFRM8m6du0aAwYMiCVLljSW7dmzJ78fOnRos22++OKL/YKwzp07538eKJ8rLS3NH3LvCwAAAAA6xJ5kmaqqqnzm2MCBA2Pw4MExY8aM2LFjR37aZWbs2LFRXl6eL5nMjBw5Mj8R84ILLoghQ4bEhx9+GPfee29e3hCWAQAAAMBhFZKNHj06Nm/eHFOnTo26urqorKyMmpqaxs38a2trm8wcu+eee6KkpCT/c8OGDXHiiSfmAdnDDz/cuk8CAAAAAG2xJ9mRttYUAAAAgMNLh9iTDAAAAACOREIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJLXopCsuro6Kioqolu3bjFkyJBYvnz5t9bfunVr3HrrrXHSSSdFaWlpnHXWWbFo0aKW9hkAAAAAWlWXYhvMnz8/qqqqYtasWXlANmPGjBgxYkSsXbs2evbsuV/9Xbt2xeWXX55/bcGCBVFeXh6ffvppHHfcca31DAAAAADwvZQUCoVCMQ2yYGzQoEExc+bM/H7Pnj3Rp0+fmDBhQkyePHm/+lmY9vjjj8eaNWviqKOOalEn6+vro3v37rFt27YoKytr0WsAAAAAcPirP0Q5UVHLLbNZYStWrIjhw4f/9wU6dcrvly1b1mybV199NYYOHZovt+zVq1f069cvHnnkkdi9e/cB32fnzp35A+99AQAAAMChUlRItmXLljzcysKuvWX3dXV1zbZZt25dvswya5ftQ3bvvffGk08+GQ899NAB32f69Ol5IthwZTPVAAAAAOCwPd0yW46Z7Uf27LPPxoABA2L06NFx991358swD2TKlCn5lLmGa/369Ye6mwAAAAAkrKiN+3v06BGdO3eOjRs3NinP7nv37t1sm+xEy2wvsqxdg3POOSefeZYt3+zatet+bbITMLMLAAAAADrcTLIs0Mpmgy1ZsqTJTLHsPtt3rDmXXHJJfPjhh3m9Bh988EEenjUXkAEAAABAh19uWVVVFbNnz44//vGPsXr16vjVr34VO3bsiPHjx+dfHzt2bL5cskH29c8//zxuv/32PBxbuHBhvnF/tpE/AAAAABx2yy0z2Z5imzdvjqlTp+ZLJisrK6OmpqZxM//a2tr8xMsG2ab7ixcvjokTJ8b5558f5eXleWA2adKk1n0SAAAAAGihkkKhUIgOrr6+Pj/lMtvEv6ysrL27AwAAAMARlhMd8tMtAQAAAKCjE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJE5IBAAAAkDwhGQAAAADJa1FIVl1dHRUVFdGtW7cYMmRILF++/KDazZs3L0pKSmLUqFEteVsAAAAA6Bgh2fz586OqqiqmTZsWK1eujP79+8eIESNi06ZN39ruk08+iTvvvDOGDRv2ffoLAAAAAO0fkj311FNx0003xfjx4+Pcc8+NWbNmxTHHHBMvvPDCAdvs3r07rrvuurj//vvjxz/+8fftMwAAAAC0X0i2a9euWLFiRQwfPvy/L9CpU36/bNmyA7Z74IEHomfPnnHDDTcc1Pvs3Lkz6uvrm1wAAAAA0CFCsi1btuSzwnr16tWkPLuvq6trts1bb70Vzz//fMyePfug32f69OnRvXv3xqtPnz7FdBMAAAAAOs7pltu3b4/rr78+D8h69Ohx0O2mTJkS27Zta7zWr19/KLsJAAAAQOK6FFM5C7o6d+4cGzdubFKe3ffu3Xu/+h999FG+Yf/IkSMby/bs2fN/b9ylS6xduzZOP/30/dqVlpbmFwAAAAB0uJlkXbt2jQEDBsSSJUuahF7Z/dChQ/er37dv33jvvfdi1apVjdfPfvazuOyyy/K/W0YJAAAAwGE3kyxTVVUV48aNi4EDB8bgwYNjxowZsWPHjvy0y8zYsWOjvLw831esW7du0a9fvybtjzvuuPzPfcsBAAAA4LAJyUaPHh2bN2+OqVOn5pv1V1ZWRk1NTeNm/rW1tfmJlwAAAABwuCgpFAqF6ODq6+vzUy6zTfzLysrauzsAAAAAHGE5kSlfAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8oRkAAAAACRPSAYAAABA8loUklVXV0dFRUV069YthgwZEsuXLz9g3dmzZ8ewYcPi+OOPz6/hw4d/a30AAAAA6PAh2fz586OqqiqmTZsWK1eujP79+8eIESNi06ZNzdZfunRpjBkzJt54441YtmxZ9OnTJ6644orYsGFDa/QfAAAAAL63kkKhUCimQTZzbNCgQTFz5sz8fs+ePXnwNWHChJg8efJ3tt+9e3c+oyxrP3bs2IN6z/r6+ujevXts27YtysrKiukuAAAAAEeQ+kOUExU1k2zXrl2xYsWKfMlk4wt06pTfZ7PEDsYXX3wRX3/9dZxwwgkHrLNz5878gfe+AAAAAOBQKSok27JlSz4TrFevXk3Ks/u6urqDeo1JkybFySef3CRo29f06dPzRLDhymaqAQAAAMARcbrlo48+GvPmzYuXX3453/T/QKZMmZJPmWu41q9f35bdBAAAACAxXYqp3KNHj+jcuXNs3LixSXl237t3729t+8QTT+Qh2V//+tc4//zzv7VuaWlpfgEAAABAh5tJ1rVr1xgwYEAsWbKksSzbuD+7Hzp06AHbPfbYY/Hggw9GTU1NDBw48Pv1GAAAAADacyZZpqqqKsaNG5eHXYMHD44ZM2bEjh07Yvz48fnXsxMry8vL833FMr///e9j6tSpMXfu3KioqGjcu+wHP/hBfgEAAADAYReSjR49OjZv3pwHX1ngVVlZmc8Qa9jMv7a2Nj/xssEzzzyTn4p59dVXN3mdadOmxX333dcazwAAAAAA30tJoVAoRAdXX1+fn3KZbeJfVlbW3t0BAAAA4AjLidr0dEsAAAAA6IiEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPKEZAAAAAAkT0gGAAAAQPJaFJJVV1dHRUVFdOvWLYYMGRLLly//1vovvvhi9O3bN69/3nnnxaJFi1raXwAAAABo/5Bs/vz5UVVVFdOmTYuVK1dG//79Y8SIEbFp06Zm67/99tsxZsyYuOGGG+Ldd9+NUaNG5df777/fGv0HAAAAgO+tpFAoFIppkM0cGzRoUMycOTO/37NnT/Tp0ycmTJgQkydP3q/+6NGjY8eOHfHaa681ll100UVRWVkZs2bNOqj3rK+vj+7du8e2bduirKysmO4CAAAAcASpP0Q5UZdiKu/atStWrFgRU6ZMaSzr1KlTDB8+PJYtW9Zsm6w8m3m2t2zm2SuvvHLA99m5c2d+NcgeuuEfAQAAAIB01f//fKjIeV+tG5Jt2bIldu/eHb169WpSnt2vWbOm2TZ1dXXN1s/KD2T69Olx//3371eezVgDAAAAgH//+9/5jLJ2CcnaSjZTbe/ZZ1u3bo0f/ehHUVtb26oPD7ROgp8F2OvXr7ccGjogYxQ6LuMTOjZjFDqubMXhqaeeGieccEKrvm5RIVmPHj2ic+fOsXHjxibl2X3v3r2bbZOVF1M/U1paml/7ygIy/zlBx5SNTeMTOi5jFDou4xM6NmMUOq5sC7BWfb1iKnft2jUGDBgQS5YsaSzLNu7P7ocOHdpsm6x87/qZ119//YD1AQAAAKCtFb3cMlsGOW7cuBg4cGAMHjw4ZsyYkZ9eOX78+PzrY8eOjfLy8nxfscztt98eP/3pT+PJJ5+Mq666KubNmxfvvPNOPPvss63/NAAAAADQFiHZ6NGjY/PmzTF16tR88/3Kysqoqalp3Jw/2zds7+luF198ccydOzfuueeeuOuuu+LMM8/MT7bs16/fQb9ntvRy2rRpzS7BBNqX8QkdmzEKHZfxCR2bMQrpjc+SQmuflwkAAAAAh5nW3eEMAAAAAA5DQjIAAAAAkickAwAAACB5QjIAAAAAktdhQrLq6uqoqKiIbt26xZAhQ2L58uXfWv/FF1+Mvn375vXPO++8WLRoUZv1FVJTzPicPXt2DBs2LI4//vj8Gj58+HeOZ6Btv4c2mDdvXpSUlMSoUaMOeR8hVcWOz61bt8att94aJ510Un5i11lnneXnXOhAY3TGjBlx9tlnx9FHHx19+vSJiRMnxldffdVm/YVUvPnmmzFy5Mg4+eST859XX3nlle9ss3Tp0rjwwgvz759nnHFGzJkz5/AMyebPnx9VVVX58Z0rV66M/v37x4gRI2LTpk3N1n/77bdjzJgxccMNN8S7776b/3CfXe+//36b9x2OdMWOz+w/pmx8vvHGG7Fs2bL8h4crrrgiNmzY0OZ9hxQUO0YbfPLJJ3HnnXfmoTbQMcbnrl274vLLL8/H54IFC2Lt2rX5h0/l5eVt3ndIQbFjdO7cuTF58uS8/urVq+P555/PX+Ouu+5q877DkW7Hjh35mMyC7IPx8ccfx1VXXRWXXXZZrFq1Ku6444648cYbY/HixUW9b0mhUChEO8sS+0GDBsXMmTPz+z179uS/WE+YMCH/T2hfo0ePzv/BXnvttcayiy66KCorK2PWrFlt2nc40hU7Pve1e/fufEZZ1n7s2LFt0GNIS0vGaDYuf/KTn8Qvf/nL+Pvf/57PXDmYT+eAQzs+s59jH3/88VizZk0cddRR7dBjSEuxY/S2227Lw7ElS5Y0lv3mN7+Jf/7zn/HWW2+1ad8hJSUlJfHyyy9/6+qHSZMmxcKFC5tMnrrmmmvyn3NramoOn5lk2SdmK1asyJdkNejUqVN+n81CaU5Wvnf9TJb4H6g+0Hbjc19ffPFFfP3113HCCSccwp5Cmlo6Rh944IHo2bNnPiMb6Djj89VXX42hQ4fmyy179eoV/fr1i0ceeSQPtoH2H6MXX3xx3qZhSea6devy5dBXXnllm/UbiEOaE3WJdrZly5b8G3/2g8DesvvsU7Tm1NXVNVs/Kwfad3w2l+hn68j3/Q8LaJ8xmn3SnS0PyaahAx1rfGa/cP/tb3+L6667Lv/F+8MPP4xf//rX+YdN2fIuoH3H6LXXXpu3u/TSSyNbkPXNN9/ELbfcYrkldAAHyonq6+vjyy+/zPcRPCxmkgFHrkcffTTfGDybGptthgq0r+3bt8f111+f73HUo0eP9u4OsI9sqVc2y/PZZ5+NAQMG5FuM3H333bYTgQ4i23s3m9359NNP53uYvfTSS/nyrgcffLC9uwa0knafSZb9kN65c+fYuHFjk/Lsvnfv3s22ycqLqQ+03fhs8MQTT+Qh2V//+tc4//zzD3FPIU3FjtGPPvoo3xA8Oylo71/KM126dMk3CT/99NPboOdw5GvJ99DsRMtsL7KsXYNzzjkn/3Q8WxrWtWvXQ95vSEVLxui9996bf9iUbQaeOe+88/K9sm+++eY80M6WawLt40A5UVlZ2UHPIsu0+yjOvtlnn5Ttvflh9gN7dp/tydCcrHzv+pnXX3/9gPWBthufmcceeyz/RC3bIHHgwIFt1FtIT7FjtG/fvvHee+/lSy0brp/97GeNpwBlmxUD7fc99JJLLsmXWDaE15kPPvggD88EZND+YzTba3ffIKwh1O4A5+FB0oa2Vk5U6ADmzZtXKC0tLcyZM6fwr3/9q3DzzTcXjjvuuEJdXV3+9euvv74wefLkxvr/+Mc/Cl26dCk88cQThdWrVxemTZtWOOqoowrvvfdeOz4FHJmKHZ+PPvpooWvXroUFCxYUPvvss8Zr+/bt7fgUcOQqdozua9y4cYWf//znbdhjSEex47O2trZw7LHHFm677bbC2rVrC6+99lqhZ8+ehYceeqgdnwKOXMWO0ez3zmyM/ulPfyqsW7eu8Je//KVw+umnF37xi1+041PAkWn79u2Fd999N7+y6Oqpp57K//7pp5/mX8/GZjZGG2Rj8phjjin89re/zXOi6urqQufOnQs1NTVFvW+7L7fMZPstbN68OaZOnZpPJ6+srMxnoDRsulZbW9sksc9OFZk7d27cc889+SaJZ555Zn50fXYCENC+4/OZZ57Jl4RcffXVTV4n23D4vvvua/P+w5Gu2DEKdNzxmc3mXLx4cUycODHfqqC8vDxuv/32/BAcoP3HaPb7Z0lJSf7nhg0b4sQTT8y3MHj44Yfb8SngyPTOO+/kqx0aVFVV5X+OGzcu5syZE5999lk+Rhucdtpp+R6B2ffQP/zhD3HKKafEc889l59wWYySLClrxecAAAAAgMOOj5YBAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkFR2SvfnmmzFy5Mg4+eSTo6SkJF555ZXvbLN06dK48MILo7S0NM4444yYM2dOS/sLAAAAAO0fku3YsSP69+8f1dXVB1X/448/jquuuiouu+yyWLVqVdxxxx1x4403xuLFi1vSXwAAAABodSWFQqHQ4sYlJfHyyy/HqFGjDlhn0qRJsXDhwnj//fcby6655prYunVr1NTUtPStAQAAAODw2ZNs2bJlMXz48CZlI0aMyMsBAAAAoCPocqjfoK6uLnr16tWkLLuvr6+PL7/8Mo4++uj92uzcuTO/GuzZsyc+//zz+OEPf5jPXgMAAAAgTYVCIbZv357vl9+pU6fDJyRrienTp8f999/f3t0AAAAAoINav359nHLKKYdPSNa7d+/YuHFjk7LsvqysrNlZZJkpU6ZEVVVV4/22bdvi1FNPzR8+awcAAABAmurr66NPnz5x7LHHturrHvKQbOjQobFo0aImZa+//npefiClpaX5ta8sIBOSAQAAAFDSyltyFb1w8z//+U+sWrUqvzIff/xx/vfa2trGWWBjx45trH/LLbfEunXr4ne/+12sWbMmnn766fjzn/8cEydObM3nAAAAAIC2C8neeeeduOCCC/Irky2LzP4+derU/P6zzz5rDMwyp512WixcuDCfPda/f/948skn47nnnstPuAQAAACAjqCkkB0JcBisNe3evXu+N5nllgAAAADpqj9EOVHrnZMJAAAAAIcpIRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyROSAQAAAJA8IRkAAAAAyWtRSFZdXR0VFRXRrVu3GDJkSCxfvvxb68+YMSPOPvvsOProo6NPnz4xceLE+Oqrr1raZwAAAABo35Bs/vz5UVVVFdOmTYuVK1dG//79Y8SIEbFp06Zm68+dOzcmT56c11+9enU8//zz+WvcddddrdF/AAAAAGj7kOypp56Km266KcaPHx/nnntuzJo1K4455ph44YUXmq3/9ttvxyWXXBLXXnttPvvsiiuuiDFjxnzn7DMAAAAA6JAh2a5du2LFihUxfPjw/75Ap075/bJly5ptc/HFF+dtGkKxdevWxaJFi+LKK6884Pvs3Lkz6uvrm1wAAAAAcKh0Kabyli1bYvfu3dGrV68m5dn9mjVrmm2TzSDL2l166aVRKBTim2++iVtuueVbl1tOnz497r///mK6BgAAAAAd93TLpUuXxiOPPBJPP/10vofZSy+9FAsXLowHH3zwgG2mTJkS27Zta7zWr19/qLsJAAAAQMKKmknWo0eP6Ny5c2zcuLFJeXbfu3fvZtvce++9cf3118eNN96Y35933nmxY8eOuPnmm+Puu+/Ol2vuq7S0NL8AAAAAoMPNJOvatWsMGDAglixZ0li2Z8+e/H7o0KHNtvniiy/2C8KyoC2TLb8EAAAAgMNqJlmmqqoqxo0bFwMHDozBgwfHjBkz8plh2WmXmbFjx0Z5eXm+r1hm5MiR+YmYF1xwQQwZMiQ+/PDDfHZZVt4QlgEAAADAYRWSjR49OjZv3hxTp06Nurq6qKysjJqamsbN/Gtra5vMHLvnnnuipKQk/3PDhg1x4okn5gHZww8/3LpPAgAAAAAtVFI4DNY81tfXR/fu3fNN/MvKytq7OwAAAAAcYTnRIT/dEgAAAAA6OiEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQPCEZAAAAAMkTkgEAAACQvBaFZNXV1VFRURHdunWLIUOGxPLly7+1/tatW+PWW2+Nk046KUpLS+Oss86KRYsWtbTPAAAAANCquhTbYP78+VFVVRWzZs3KA7IZM2bEiBEjYu3atdGzZ8/96u/atSsuv/zy/GsLFiyI8vLy+PTTT+O4445rrWcAAAAAgO+lpFAoFIppkAVjgwYNipkzZ+b3e/bsiT59+sSECRNi8uTJ+9XPwrTHH3881qxZE0cddVSLOllfXx/du3ePbdu2RVlZWYteAwAAAIDDX/0hyomKWm6ZzQpbsWJFDB8+/L8v0KlTfr9s2bJm27z66qsxdOjQfLllr169ol+/fvHII4/E7t27D/g+O3fuzB947wsAAAAADpWiQrItW7bk4VYWdu0tu6+rq2u2zbp16/Jlllm7bB+ye++9N5588sl46KGHDvg+06dPzxPBhiubqQYAAAAAh+3pltlyzGw/smeffTYGDBgQo0ePjrvvvjtfhnkgU6ZMyafMNVzr168/1N0EAAAAIGFFbdzfo0eP6Ny5c2zcuLFJeXbfu3fvZttkJ1pme5Fl7Rqcc845+cyzbPlm165d92uTnYCZXQAAAADQ4WaSZYFWNhtsyZIlTWaKZffZvmPNueSSS+LDDz/M6zX44IMP8vCsuYAMAAAAADr8csuqqqqYPXt2/PGPf4zVq1fHr371q9ixY0eMHz8+//rYsWPz5ZINsq9//vnncfvtt+fh2MKFC/ON+7ON/AEAAADgsFtumcn2FNu8eXNMnTo1XzJZWVkZNTU1jZv519bW5ideNsg23V+8eHFMnDgxzj///CgvL88Ds0mTJrXukwAAAABAC5UUCoVCdHD19fX5KZfZJv5lZWXt3R0AAAAAjrCc6JCfbgkAAAAAHZ2QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASJ6QDAAAAIDkCckAAAAASF6LQrLq6uqoqKiIbt26xZAhQ2L58uUH1W7evHlRUlISo0aNasnbAgAAAEDHCMnmz58fVVVVMW3atFi5cmX0798/RowYEZs2bfrWdp988knceeedMWzYsO/TXwAAAABo/5DsqaeeiptuuinGjx8f5557bsyaNSuOOeaYeOGFFw7YZvfu3XHdddfF/fffHz/+8Y+/b58BAAAAoP1Csl27dsWKFSti+PDh/32BTp3y+2XLlh2w3QMPPBA9e/aMG2644fv1FgAAAAAOgS7FVN6yZUs+K6xXr15NyrP7NWvWNNvmrbfeiueffz5WrVp10O+zc+fO/GpQX19fTDcBAAAAoOOcbrl9+/a4/vrrY/bs2dGjR4+Dbjd9+vTo3r1749WnT59D2U0AAAAAElfUTLIs6OrcuXNs3LixSXl237t37/3qf/TRR/mG/SNHjmws27Nnz/+9cZcusXbt2jj99NP3azdlypT8cIC9Z5IJygAAAADoECFZ165dY8CAAbFkyZIYNWpUY+iV3d9222371e/bt2+89957TcruueeefIbZH/7whwMGX6WlpfkFAAAAAB0uJMtkM7zGjRsXAwcOjMGDB8eMGTNix44d+WmXmbFjx0Z5eXm+ZLJbt27Rr1+/Ju2PO+64/M99ywEAAADgsAnJRo8eHZs3b46pU6dGXV1dVFZWRk1NTeNm/rW1tfmJlwAAAABwuCgpFAqF6OCyPcmyDfy3bdsWZWVl7d0dAAAAAI6wnMiULwAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHlCMgAAAACSJyQDAAAAIHktCsmqq6ujoqIiunXrFkOGDInly5cfsO7s2bNj2LBhcfzxx+fX8OHDv7U+AAAAAHT4kGz+/PlRVVUV06ZNi5UrV0b//v1jxIgRsWnTpmbrL126NMaMGRNvvPFGLFu2LPr06RNXXHFFbNiwoTX6DwAAAADfW0mhUCgU0yCbOTZo0KCYOXNmfr9nz548+JowYUJMnjz5O9vv3r07n1GWtR87duxBvWd9fX107949tm3bFmVlZcV0FwAAAIAjSP0hyomKmkm2a9euWLFiRb5ksvEFOnXK77NZYgfjiy++iK+//jpOOOGEA9bZuXNn/sB7XwAAAABwqBQVkm3ZsiWfCdarV68m5dl9XV3dQb3GpEmT4uSTT24StO1r+vTpeSLYcGUz1QAAAADgiDjd8tFHH4158+bFyy+/nG/6fyBTpkzJp8w1XOvXr2/LbgIAAACQmC7FVO7Ro0d07tw5Nm7c2KQ8u+/du/e3tn3iiSfykOyvf/1rnH/++d9at7S0NL8AAAAAoMPNJOvatWsMGDAglixZ0liWbdyf3Q8dOvSA7R577LF48MEHo6amJgYOHPj9egwAAAAA7TmTLFNVVRXjxo3Lw67BgwfHjBkzYseOHTF+/Pj869mJleXl5fm+Ypnf//73MXXq1Jg7d25UVFQ07l32gx/8IL8AAAAA4LALyUaPHh2bN2/Og68s8KqsrMxniDVs5l9bW5ufeNngmWeeyU/FvPrqq5u8zrRp0+K+++5rjWcAAAAAgO+lpFAoFKKDq6+vz0+5zDbxLysra+/uAAAAAHCE5URterolAAAAAHREQjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5QjIAAAAAkickAwAAACB5LQrJqquro6KiIrp16xZDhgyJ5cuXf2v9F198Mfr27ZvXP++882LRokUt7S8AAAAAtLqiQ7L58+dHVVVVTJs2LVauXBn9+/ePESNGxKZNm5qt//bbb8eYMWPihhtuiHfffTdGjRqVX++//35r9B8AAAAAvreSQqFQKKZBNnNs0KBBMXPmzPx+z5490adPn5gwYUJMnjx5v/qjR4+OHTt2xGuvvdZYdtFFF0VlZWXMmjXroN6zvr4+unfvHtu2bYuysrJiugsAAADAEaT+EOVEXYqpvGvXrlixYkVMmTKlsaxTp04xfPjwWLZsWbNtsvJs5tnesplnr7zyygHfZ+fOnfnVIHvohn8EAAAAANJV///zoSLnfbVuSLZly5bYvXt39OrVq0l5dr9mzZpm29TV1TVbPys/kOnTp8f999+/X3k2Yw0AAAAA/v3vf+czytolJGsr2Uy1vWefbd26NX70ox9FbW1tqz480DoJfhZgr1+/3nJo6ICMUei4jE/o2IxR6LiyFYennnpqnHDCCa36ukWFZD169IjOnTvHxo0bm5Rn97179262TVZeTP1MaWlpfu0rC8j85wQdUzY2jU/ouIxR6LiMT+jYjFHouLItwFr19Yqp3LVr1xgwYEAsWbKksSzbuD+7Hzp0aLNtsvK962def/31A9YHAAAAgLZW9HLLbBnkuHHjYuDAgTF48OCYMWNGfnrl+PHj86+PHTs2ysvL833FMrfffnv89Kc/jSeffDKuuuqqmDdvXrzzzjvx7LPPtv7TAAAAAEBbhGSjR4+OzZs3x9SpU/PN9ysrK6OmpqZxc/5s37C9p7tdfPHFMXfu3LjnnnvirrvuijPPPDM/2bJfv34H/Z7Z0stp06Y1uwQTaF/GJ3Rsxih0XMYndGzGKKQ3PksKrX1eJgAAAAAcZlp3hzMAAAAAOAwJyQAAAABInpAMAAAAgOQJyQAAAABIXocJyaqrq6OioiK6desWQ4YMieXLl39r/RdffDH69u2b1z/vvPNi0aJFbdZXSE0x43P27NkxbNiwOP744/Nr+PDh3zmegbb9Htpg3rx5UVJSEqNGjTrkfYRUFTs+t27dGrfeemucdNJJ+YldZ511lp9zoQON0RkzZsTZZ58dRx99dPTp0ycmTpwYX331VZv1F1Lx5ptvxsiRI+Pkk0/Of1595ZVXvrPN0qVL48ILL8y/f55xxhkxZ86cwzMkmz9/flRVVeXHd65cuTL69+8fI0aMiE2bNjVb/+23344xY8bEDTfcEO+++27+w312vf/++23edzjSFTs+s/+YsvH5xhtvxLJly/IfHq644orYsGFDm/cdUlDsGG3wySefxJ133pmH2kDHGJ+7du2Kyy+/PB+fCxYsiLVr1+YfPpWXl7d53yEFxY7RuXPnxuTJk/P6q1evjueffz5/jbvuuqvN+w5Huh07duRjMguyD8bHH38cV111VVx22WWxatWquOOOO+LGG2+MxYsXF/W+JYVCoRDtLEvsBw0aFDNnzszv9+zZk/9iPWHChPw/oX2NHj06/wd77bXXGssuuuiiqKysjFmzZrVp3+FIV+z43Nfu3bvzGWVZ+7Fjx7ZBjyEtLRmj2bj8yU9+Er/85S/j73//ez5z5WA+nQMO7fjMfo59/PHHY82aNXHUUUe1Q48hLcWO0dtuuy0Px5YsWdJY9pvf/Cb++c9/xltvvdWmfYeUlJSUxMsvv/ytqx8mTZoUCxcubDJ56pprrsl/zq2pqTl8ZpJln5itWLEiX5LVoFOnTvl9NgulOVn53vUzWeJ/oPpA243PfX3xxRfx9ddfxwknnHAIewppaukYfeCBB6Jnz575jGyg44zPV199NYYOHZovt+zVq1f069cvHnnkkTzYBtp/jF588cV5m4YlmevWrcuXQ1955ZVt1m8gDmlO1CXa2ZYtW/Jv/NkPAnvL7rNP0ZpTV1fXbP2sHGjf8dlcop+tI9/3PyygfcZo9kl3tjwkm4YOdKzxmf3C/be//S2uu+66/BfvDz/8MH7961/nHzZly7uA9h2j1157bd7u0ksvjWxB1jfffBO33HKL5ZbQARwoJ6qvr48vv/wy30fwsJhJBhy5Hn300Xxj8GxqbLYZKtC+tm/fHtdff32+x1GPHj3auzvAPrKlXtksz2effTYGDBiQbzFy9913204EOohs791sdufTTz+d72H20ksv5cu7HnzwwfbuGtBK2n0mWfZDeufOnWPjxo1NyrP73r17N9smKy+mPtB247PBE088kYdkf/3rX+P8888/xD2FNBU7Rj/66KN8Q/DspKC9fynPdOnSJd8k/PTTT2+DnsORryXfQ7MTLbO9yLJ2Dc4555z80/FsaVjXrl0Peb8hFS0Zo/fee2/+YVO2GXjmvPPOy/fKvvnmm/NAO1uuCbSPA+VEZWVlBz2LLNPuozj7Zp99Urb35ofZD+zZfbYnQ3Oy8r3rZ15//fUD1gfabnxmHnvssfwTtWyDxIEDB7ZRbyE9xY7Rvn37xnvvvZcvtWy4fvaznzWeApRtVgy03/fQSy65JF9i2RBeZz744IM8PBOQQfuP0Wyv3X2DsIZQuwOchwdJG9paOVGhA5g3b16htLS0MGfOnMK//vWvws0331w47rjjCnV1dfnXr7/++sLkyZMb6//jH/8odOnSpfDEE08UVq9eXZg2bVrhqKOOKrz33nvt+BRwZCp2fD766KOFrl27FhYsWFD47LPPGq/t27e341PAkavYMbqvcePGFX7+85+3YY8hHcWOz9ra2sKxxx5buO222wpr164tvPbaa4WePXsWHnrooXZ8CjhyFTtGs987szH6pz/9qbBu3brCX/7yl8Lpp59e+MUvftGOTwFHpu3btxfefffd/Mqiq6eeeir/+6effpp/PRub2RhtkI3JY445pvDb3/42z4mqq6sLnTt3LtTU1BT1vu2+3DKT7bewefPmmDp1aj6dvLKyMp+B0rDpWm1tbZPEPjtVZO7cuXHPPffkmySeeeaZ+dH12QlAQPuOz2eeeSZfEnL11Vc3eZ1sw+H77ruvzfsPR7pixyjQccdnNptz8eLFMXHixHyrgvLy8rj99tvzQ3CA9h+j2e+fJSUl+Z8bNmyIE088Md/C4OGHH27Hp4Aj0zvvvJOvdmhQVVWV/zlu3LiYM2dOfPbZZ/kYbXDaaaflewRm30P/8Ic/xCmnnBLPPfdcfsJlMUqypKwVnwMAAAAADjs+WgYAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAAJInJAMAAAAgeUIyAAAAACJ1/w8SK2WAnIiJ8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.plotter import LSTMPlotter\n",
    "\n",
    "plotter = LSTMPlotter(rows=3, cols=1)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 26.5090 - mape: 26.5090 - mse: 16381.4463 - val_loss: 1.2898 - val_mape: 1.2898 - val_mse: 30.2636\n",
      "Epoch 2/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.7804 - mape: 5.7804 - mse: 440.8709 - val_loss: 1.2873 - val_mape: 1.2873 - val_mse: 29.7674\n",
      "Epoch 3/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.9158 - mape: 5.9158 - mse: 464.7364 - val_loss: 1.0539 - val_mape: 1.0539 - val_mse: 20.5976\n",
      "Epoch 4/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8330 - mape: 5.8330 - mse: 446.3437 - val_loss: 3.8180 - val_mape: 3.8180 - val_mse: 239.1942\n",
      "Epoch 5/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8136 - mape: 5.8136 - mse: 451.3073 - val_loss: 2.1965 - val_mape: 2.1965 - val_mse: 81.0722\n",
      "Epoch 6/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.8821 - mape: 5.8821 - mse: 448.4301 - val_loss: 0.3966 - val_mape: 0.3966 - val_mse: 4.6646\n",
      "Epoch 7/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8222 - mape: 5.8222 - mse: 446.7459 - val_loss: 1.0925 - val_mape: 1.0925 - val_mse: 21.9615\n",
      "Epoch 8/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8168 - mape: 5.8168 - mse: 443.4967 - val_loss: 1.1218 - val_mape: 1.1218 - val_mse: 22.9989\n",
      "Epoch 9/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6099 - mape: 5.6099 - mse: 414.4262 - val_loss: 1.9916 - val_mape: 1.9916 - val_mse: 67.2853\n",
      "Epoch 10/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7117 - mape: 5.7117 - mse: 433.6932 - val_loss: 1.0304 - val_mape: 1.0304 - val_mse: 19.7546\n",
      "Epoch 11/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6348 - mape: 5.6348 - mse: 412.3421 - val_loss: 1.5176 - val_mape: 1.5176 - val_mse: 40.2679\n",
      "Epoch 12/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5710 - mape: 5.5710 - mse: 412.6767 - val_loss: 0.6197 - val_mape: 0.6197 - val_mse: 8.4666\n",
      "Epoch 13/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6463 - mape: 5.6463 - mse: 423.9470 - val_loss: 3.8241 - val_mape: 3.8241 - val_mse: 239.4907\n",
      "Epoch 14/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8111 - mape: 5.8111 - mse: 445.7621 - val_loss: 0.5968 - val_mape: 0.5968 - val_mse: 8.2576\n",
      "Epoch 15/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7171 - mape: 5.7171 - mse: 424.1749 - val_loss: 2.2102 - val_mape: 2.2102 - val_mse: 82.0451\n",
      "Epoch 16/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7952 - mape: 5.7952 - mse: 454.0234 - val_loss: 3.0891 - val_mape: 3.0891 - val_mse: 157.8710\n",
      "Epoch 1/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 23.3261 - mape: 23.3261 - mse: 11865.5195 - val_loss: 1.6228 - val_mape: 1.6228 - val_mse: 45.5319\n",
      "Epoch 2/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.0405 - mape: 6.0405 - mse: 480.8387 - val_loss: 0.3943 - val_mape: 0.3943 - val_mse: 4.6597\n",
      "Epoch 3/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6057 - mape: 5.6057 - mse: 417.1581 - val_loss: 1.9856 - val_mape: 1.9856 - val_mse: 67.3692\n",
      "Epoch 4/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8312 - mape: 5.8312 - mse: 447.6164 - val_loss: 2.1318 - val_mape: 2.1318 - val_mse: 76.3133\n",
      "Epoch 5/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6294 - mape: 5.6294 - mse: 417.0597 - val_loss: 1.5465 - val_mape: 1.5465 - val_mse: 41.5275\n",
      "Epoch 6/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.3982 - mape: 5.3982 - mse: 392.5448 - val_loss: 0.3367 - val_mape: 0.3367 - val_mse: 3.6696\n",
      "Epoch 7/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6535 - mape: 5.6535 - mse: 414.7725 - val_loss: 1.1833 - val_mape: 1.1833 - val_mse: 25.3850\n",
      "Epoch 8/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5301 - mape: 5.5301 - mse: 404.0958 - val_loss: 0.3304 - val_mape: 0.3304 - val_mse: 3.5973\n",
      "Epoch 9/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6078 - mape: 5.6078 - mse: 417.8334 - val_loss: 2.1725 - val_mape: 2.1725 - val_mse: 79.4602\n",
      "Epoch 10/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4907 - mape: 5.4907 - mse: 402.8899 - val_loss: 4.2673 - val_mape: 4.2673 - val_mse: 297.8030\n",
      "Epoch 11/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6440 - mape: 5.6440 - mse: 424.7153 - val_loss: 0.2742 - val_mape: 0.2742 - val_mse: 3.0236\n",
      "Epoch 12/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4607 - mape: 5.4607 - mse: 389.9280 - val_loss: 0.3968 - val_mape: 0.3968 - val_mse: 4.5204\n",
      "Epoch 13/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.3308 - mape: 5.3308 - mse: 372.5296 - val_loss: 0.5560 - val_mape: 0.5560 - val_mse: 7.1116\n",
      "Epoch 14/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5192 - mape: 5.5192 - mse: 409.8461 - val_loss: 1.3992 - val_mape: 1.3992 - val_mse: 34.2198\n",
      "Epoch 15/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.3745 - mape: 5.3745 - mse: 393.1609 - val_loss: 3.2822 - val_mape: 3.2822 - val_mse: 177.6964\n",
      "Epoch 16/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6098 - mape: 5.6098 - mse: 418.0021 - val_loss: 0.2888 - val_mape: 0.2888 - val_mse: 3.0699\n",
      "Epoch 17/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4579 - mape: 5.4579 - mse: 401.3795 - val_loss: 0.8815 - val_mape: 0.8815 - val_mse: 14.8640\n",
      "Epoch 18/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.3165 - mape: 5.3165 - mse: 373.9121 - val_loss: 2.6878 - val_mape: 2.6878 - val_mse: 119.5490\n",
      "Epoch 19/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.6009 - mape: 5.6009 - mse: 420.6992 - val_loss: 0.7144 - val_mape: 0.7144 - val_mse: 10.3044\n",
      "Epoch 20/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5172 - mape: 5.5172 - mse: 400.7259 - val_loss: 1.7194 - val_mape: 1.7194 - val_mse: 51.0588\n",
      "Epoch 21/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5554 - mape: 5.5554 - mse: 405.8076 - val_loss: 2.3483 - val_mape: 2.3483 - val_mse: 92.2096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,3):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Bidirectional(LSTM(units=lstm_complexity, activation='relu')))\n",
    "    # model.add(Bidirectional(LSTM(units=32)))\n",
    "    # model.add(Bidirectional(LSTM(units=lstm_complexity)))\n",
    "    model.add(Dropout(0.3))\n",
    "    # model.add(LSTM(units=50, return_sequences=False))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "    # print(model.summary())\n",
    "\n",
    "    cp_path = f'model_cp_{i}.keras'\n",
    "    if os.path.exists(cp_path):\n",
    "        os.remove(cp_path)\n",
    "        \n",
    "    cp = ModelCheckpoint(cp_path, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='mape', metrics=['mse', 'mape'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batches, callbacks=[cp,early_stopping])\n",
    "\n",
    "    # # Load the best model\n",
    "    # model.load_weights(cp_path)\n",
    "    # # Evaluate the model on the test set\n",
    "    # test_loss = model.evaluate(X_test, y_test)\n",
    "    # print(test_loss)\n",
    "    \n",
    "    # # Make predictions on the test set\n",
    "    # y_pred = model.predict(X_test)\n",
    "        \n",
    "    # plotter.add_plot(y_test, y_pred, cp_path)\n",
    "    \n",
    "    # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_percentage_error, mean_squared_error\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Compute Metrics\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m mape \u001b[38;5;241m=\u001b[39m mean_absolute_percentage_error(y_test, \u001b[43my_pred\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      8\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m      9\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "\n",
    "# Compute Metrics\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.plot(y_test, color='blue', label='Actual Closing Price')\n",
    "plt.plot(y_pred, color='red', label='Predicted Closing Price')\n",
    "\n",
    "# Add Title and Labels\n",
    "plt.gca().set_xticklabels(df[train_split+val_split:].index)\n",
    "plt.title('Stock Closing Price Prediction', fontsize=20)\n",
    "plt.xlabel('Time', fontsize=16)\n",
    "plt.ylabel('Stock Closing Price', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# Display metrics on the plot\n",
    "metrics_text = f\"MAPE: {mape:.2f}%\\nRMSE: {rmse:.2f}\\nMSE: {mse:.2f}\"\n",
    "plt.text(2, max(y_test) * 0.995, metrics_text, fontsize=18, color='black', \n",
    "         bbox=dict(facecolor='white', alpha=0.6))\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIGNALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 2 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[275], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Simulate trades\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mn_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbuy_signal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;66;03m# Buy\u001b[39;00m\n\u001b[0;32m     64\u001b[0m         position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     65\u001b[0m         buy_price \u001b[38;5;241m=\u001b[39m n_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n",
      "File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "test=[1,2,3]\n",
    "print(type(y_test))\n",
    "\n",
    "def duplicate_features(data, n_features=len(features)):\n",
    "    return np.tile(data.reshape(-1, 1), n_features)\n",
    "\n",
    "# Duplicate y_test and y_pred to have 4 identical columns\n",
    "y_test_duplicated = duplicate_features(y_test)\n",
    "y_pred_duplicated = duplicate_features(y_pred)\n",
    "\n",
    "# Perform inverse transform\n",
    "y_test_original_duplicated = scaler.inverse_transform(y_test_duplicated)\n",
    "y_pred_original_duplicated = scaler.inverse_transform(y_pred_duplicated)\n",
    "\n",
    "# Extract the first column\n",
    "y_test_original = y_test_original_duplicated[:, 0]\n",
    "y_pred_original = y_pred_original_duplicated[:, 0]\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "# y_pred = y_pred.flatten()\n",
    "n_df = pd.DataFrame({\n",
    "    'actual': y_test_original,\n",
    "    'predicted': y_pred_original\n",
    "})\n",
    "\n",
    "# Generate trading signals\n",
    "n_df['buy_signal'] = n_df['predicted'].diff().shift(-2) > 0\n",
    "n_df['sell_signal'] = n_df['predicted'].diff().shift(-2) < 0\n",
    "\n",
    "# # Initialize variables for tracking trades\n",
    "# position = 0  # 1 for holding, 0 for not holding\n",
    "# buy_price = 0\n",
    "# total_profit = 0\n",
    "# trades = []\n",
    "\n",
    "\n",
    "# # Simulate trades\n",
    "# for i in range(len(df)):\n",
    "#     if df['buy_signal'][i] and position == 0:\n",
    "#         # Buy\n",
    "#         position = 1\n",
    "#         buy_price = df['actual'][i]\n",
    "#     elif df['sell_signal'][i] and position == 1:\n",
    "#         # Sell\n",
    "#         position = 0\n",
    "#         sell_price = df['actual'][i]\n",
    "#         profit = sell_price - buy_price\n",
    "#         total_profit += profit\n",
    "#         trades.append({'buy_price': buy_price, 'sell_price': sell_price, 'profit': profit})\n",
    "\n",
    "# Initialize variables for tracking trades\n",
    "position = 0  # 1 for holding, 0 for not holding\n",
    "buy_price = 0\n",
    "total_profit = 0\n",
    "trades = []\n",
    "\n",
    "buys = []\n",
    "\n",
    "# Simulate trades\n",
    "for i in range(len(df)):\n",
    "    if n_df['buy_signal'][i]:\n",
    "        # Buy\n",
    "        position = 1\n",
    "        buy_price = n_df['actual'][i]\n",
    "        buys.append(buy_price)\n",
    "    elif n_df['sell_signal'][i] and position == 1:\n",
    "        # Sell\n",
    "        position = 0\n",
    "        sell_price = n_df['actual'][i]\n",
    "        profit = sum(sell_price - x for x in buys)\n",
    "        total_profit += profit\n",
    "        trades.append({'buy_price': buy_price, 'sell_price': sell_price, 'profit': profit})\n",
    "        buys = []\n",
    "\n",
    "# Identify buy and sell indices\n",
    "buy_indices = n_df.index[n_df['buy_signal']].tolist()\n",
    "sell_indices = n_df.index[n_df['sell_signal']].tolist()\n",
    "\n",
    "# Convert trades to DataFrame for analysis\n",
    "trades_df = pd.DataFrame(trades)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.plot(n_df['actual'], color='blue', label='Actual Closing Price')\n",
    "plt.plot(n_df['predicted'], color='red', label='Predicted Closing Price')\n",
    "\n",
    "# Plot buy and sell signals\n",
    "plt.scatter(buy_indices, n_df['actual'][buy_indices], color='green', marker='^', s=100, label='Buy Signal')\n",
    "plt.scatter(sell_indices, n_df['actual'][sell_indices], color='orange', marker='v', s=100, label='Sell Signal')\n",
    "\n",
    "plt.title('Stock Closing Price Prediction with Buy/Sell Signals')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Closing Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.locator_params(axis='x', nbins=2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Total Profit: {total_profit:.2f}\")\n",
    "print(f\"Number of Trades: {len(trades_df)}\")\n",
    "print(f\"Average Profit per Trade: {trades_df['profit'].mean():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
